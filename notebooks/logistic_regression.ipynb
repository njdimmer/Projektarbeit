{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip\n",
    "!pip3 install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing essential libraries for text processing (nltk), machine learning (sklearn), data visualization (seaborn, matplotlib), and data manipulation (pandas, numpy).\n",
    "- Downloading NLTK stopwords and lemmatizer models to preprocess text data.\n",
    "- Suppressing unnecessary warnings for better readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Displaying the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "df = pd.read_csv('../assets/datasets/IMDb_Dataset.csv')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformating\n",
    "# Rename 'sentiment' column to 'label'\n",
    "df.rename(columns={'sentiment': 'label'}, inplace=True)\n",
    "# Convert labels to binary values\n",
    "df.label = df.label.apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the IMDb dataset containing movie reviews and their corresponding sentiments.\n",
    "- Print the shape of the dataset to understand the number of rows and columns.\n",
    "- Display the first 10 rows to preview the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove non-letters and non-digits\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "df.review = df.review.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove URLs, HTML tags, and special characters. Also converts text to lowercase for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered = [word for word in words if word not in stopwords]\n",
    "    return \" \".join(filtered)\n",
    "\n",
    "df.review = df.review.apply(remove_stopwords)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function remove_stopwords to filter out common words (e.g., \"the\", \"and\") that do not contribute to sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df.review = df.review.apply(lemmatize_text)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the WordNet lemmatizer to reduce words to their base forms (e.g., \"running\" â†’ \"run\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and shuffling\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts = train_data['review']\n",
    "train_labels = train_data['label']\n",
    "\n",
    "test_texts = test_data['review']\n",
    "test_labels = test_data['label']\n",
    "\n",
    "print(train_texts.shape, test_texts.shape)\n",
    "train_texts.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the dataset into training (80%) and testing (20%) subsets.\n",
    "- Shuffle the data with a fixed random state to ensure reproducibility.\n",
    "- Display the shape of the train and test subsets and preview some training reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_test = tfidf.transform(test_texts)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF vectorization to convert text data into numerical features. Generate unigrams and bigrams with a maximum of 5,000 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and evaluation\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(test_labels, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "report = classification_report(test_labels, y_pred, output_dict=True)\n",
    "\n",
    "categories = list(report.keys())[:2]\n",
    "precision = [report[cat]['precision'] for cat in categories]\n",
    "recall = [report[cat]['recall'] for cat in categories]\n",
    "f1_score = [report[cat]['f1-score'] for cat in categories]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "bars1 = ax.bar(x - width, precision, width, label='Precision', color='skyblue')\n",
    "bars2 = ax.bar(x, recall, width, label='Recall', color='orange')\n",
    "bars3 = ax.bar(x + width, f1_score, width, label='F1 Score', color='green')\n",
    "\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Logistic Regression - Precision, Recall, and F1 Scores by Sentiment')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    ax.bar_label(bars, fmt='%.2f', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize precision, recall, and F1 scores for positive and negative sentiments using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.title(\"Logistic Regression - Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix to visualize the model's performance in classifying positive and negative sentiments.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
